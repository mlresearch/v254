---
title: Multi-head Attention-based Deep Multiple Instance Learning
booktitle: Proceedings of the MICCAI Workshop on Computational Pathology
abstract: 'This paper introduces MAD-MIL, a Multi-head Attention-based Deep Multiple
  Instance Learning model, designed for weakly supervised Whole Slide Images (WSIs)
  classification in digital pathology. Inspired by the multi-head attention mechanism
  of the Transformer, MAD-MIL simplifies model complexity while achieving competitive
  results against advanced models like CLAM and DS-MIL. Evaluated on the MNIST-BAGS
  and public datasets, including TUPAC16, TCGA BRCA, TCGA LUNG, and TCGA KIDNEY MAD-MIL
  consistently outperforms ABMIL. This demonstrates enhanced information diversity,
  interpretability, and efficiency in slide representation. The modelâ€™s effectiveness,
  coupled with fewer trainable parameters and lower computational complexity makes
  it a promising solution for automated pathology workflows. Our code is available
  at https://github.com/tueimage/MAD-MIL.  '
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: keshvarikhojasteh24a
month: 0
tex_title: Multi-head Attention-based Deep Multiple Instance Learning
firstpage: 1
lastpage: 12
page: 1-12
order: 1
cycles: false
bibtex_author: Keshvarikhojasteh, Hassan and Pluim, Josien P. W. and Veta, Mitko
author:
- given: Hassan
  family: Keshvarikhojasteh
- given: Josien P. W.
  family: Pluim
- given: Mitko
  family: Veta
date: 2024-11-17
address:
container-title: Proceedings of the MICCAI Workshop on Computational Pathology
volume: '254'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 11
  - 17
pdf: https://raw.githubusercontent.com/mlresearch/v254/main/assets/keshvarikhojasteh24a/keshvarikhojasteh24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
